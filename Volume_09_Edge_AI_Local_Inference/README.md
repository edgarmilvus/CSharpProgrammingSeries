# Book 9: Edge AI & Local Inference. Running LLMs (Llama/Phi) locally with C# and ONNX.

Part of the **Generated Source Code Pack**.

## üìò Chapters
- [Chapter 1: Cloud vs Local - Privacy, Latency, and Cost](./Chapter_01_chapter_1_cloud_vs_local_-_privacy_latency_and_cost/README.md)
- [Chapter 2: Understanding Model Formats - ONNX vs GGUF](./Chapter_02_chapter_2_understanding_model_formats_-_onnx_vs_gguf/README.md)
- [Chapter 3: Quantization Explained (FP16, INT8, INT4)](./Chapter_03_chapter_3_quantization_explained_fp16_int8_int4/README.md)
- [Chapter 4: Hardware Acceleration - CUDA, DirectML, and NPUs](./Chapter_04_chapter_4_hardware_acceleration_-_cuda_directml_and_npus/README.md)
- [Chapter 5: Setting up the Local Environment](./Chapter_05_chapter_5_setting_up_the_local_environment/README.md)
- [Chapter 6: Introduction to LlamaSharp](./Chapter_06_chapter_6_introduction_to_llamasharp/README.md)
- [Chapter 7: Loading GGUF Models (Llama 3, Phi-3)](./Chapter_07_chapter_7_loading_gguf_models_llama_3_phi-3/README.md)
- [Chapter 8: Managing Context Windows Locally](./Chapter_08_chapter_8_managing_context_windows_locally/README.md)
- [Chapter 9: Streaming Inference to the Console](./Chapter_09_chapter_9_streaming_inference_to_the_console/README.md)
- [Chapter 10: Stateful Chat Sessions in Local Memory](./Chapter_10_chapter_10_stateful_chat_sessions_in_local_memory/README.md)
- [Chapter 11: Introduction to Microsoft.ML](./Chapter_11_chapter_11_introduction_to_microsoftml/README.md)
- [Chapter 12: Running BERT for Text Classification](./Chapter_12_chapter_12_running_bert_for_text_classification/README.md)
- [Chapter 13: Object Detection with YOLO and ONNX](./Chapter_13_chapter_13_object_detection_with_yolo_and_onnx/README.md)
- [Chapter 14: Text-to-Speech (TTS) with Local Models](./Chapter_14_chapter_14_text-to-speech_tts_with_local_models/README.md)
- [Chapter 15: Whisper.net - Local Audio Transcription](./Chapter_15_chapter_15_whispernet_-_local_audio_transcription/README.md)
- [Chapter 16: Integrating AI into WPF/Windows Forms](./Chapter_16_chapter_16_integrating_ai_into_wpfwindows_forms/README.md)
- [Chapter 17: Background Processing without Freezing UI](./Chapter_17_chapter_17_background_processing_without_freezing_ui/README.md)
- [Chapter 18: Offline RAG - Querying Local Files](./Chapter_18_chapter_18_offline_rag_-_querying_local_files/README.md)
- [Chapter 19: Fine-Tuning Basics (LoRA concepts)](./Chapter_19_chapter_19_fine-tuning_basics_lora_concepts/README.md)
- [Chapter 20: Capstone - Building a Private, Offline Coding Assistant](./Chapter_20_chapter_20_capstone_-_building_a_private_offline_coding_assi/README.md)

## üõí Check the volume details (with stores links)
- [website](https://programmingcentral.hashnode.dev/csharp-and-ai-programming-series-volume-9-ebook-edge-ai-and-local-inference-running-llms-llamaphi-locally-with-c-and-onnx)

‚Üê Back to series index: [README](../README.md)
