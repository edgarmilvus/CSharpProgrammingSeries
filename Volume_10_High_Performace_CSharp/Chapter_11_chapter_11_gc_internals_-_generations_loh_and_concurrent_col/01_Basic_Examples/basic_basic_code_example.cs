
#
# These sources are part of the "C# Programming Series" by Edgar Milvus, 
# you can find it on stores: 
# 
# https://www.amazon.com/dp/B0GKJ3NYL6 or https://tinyurl.com/CSharpProgrammingBooks or 
# https://leanpub.com/u/edgarmilvus (quantity discounts)
# 
# New books info: https://linktr.ee/edgarmilvus 
#
# MIT License
# Copyright (c) 2026 Edgar Milvus
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Source File: basic_basic_code_example.cs
# Description: Basic Code Example
# ==========================================

using System;
using System.Buffers;
using System.Diagnostics;
using System.Text;
using System.Threading;
using System.Threading.Tasks;

namespace HighPerformanceAI.GCInternals
{
    public class TokenProcessingSimulator
    {
        // Configuration for the simulation
        private const int TotalTokensToProcess = 1_000_000;
        private const int BatchSize = 10_000;

        public static async Task Main(string[] args)
        {
            Console.WriteLine($"Starting Token Processing Simulation (Total: {TotalTokensToProcess:N0})");
            Console.WriteLine("-------------------------------------------------------------");

            // 1. Baseline: Naive approach causing heavy GC pressure (Gen 0/1 collections)
            await RunNaiveTokenProcessing();

            Console.WriteLine("\n");

            // 2. Optimized approach: Using ArrayPool to reduce allocations and LOH pressure
            await RunOptimizedTokenProcessing();

            Console.WriteLine("\nSimulation Complete. Press any key to exit.");
            Console.ReadKey();
        }

        /// <summary>
        /// Simulates processing tokens by allocating new arrays for every batch.
        /// This causes frequent Gen 0 collections and potential LOH allocations if strings are large.
        /// </summary>
        private static async Task RunNaiveTokenProcessing()
        {
            Console.WriteLine(">>> SCENARIO 1: Naive Allocation (High GC Pressure)");

            var sw = Stopwatch.StartNew();
            long initialMemory = GC.GetTotalMemory(true);

            for (int i = 0; i < TotalTokensToProcess; i += BatchSize)
            {
                // Create a batch of tokens (simulating strings from an AI model)
                // In a real scenario, these might be generated by a tokenizer.
                string[] tokenBatch = new string[BatchSize];

                for (int j = 0; j < BatchSize; j++)
                {
                    // Simulate a token string. 
                    // Note: If the string length > 850 bytes (approx), it goes directly to the LOH.
                    tokenBatch[j] = $"Token_{i + j}_Data_Payload_{Guid.NewGuid()}";
                }

                // Simulate some processing (e.g., concatenation or model state update)
                StringBuilder sb = new StringBuilder();
                foreach (var token in tokenBatch)
                {
                    sb.Append(token);
                }
                string _ = sb.ToString(); // Force creation of the final string

                // Force a garbage collection check periodically to simulate pressure
                // (In production, we don't call GC.Collect(), but here we visualize it)
                if (i % (BatchSize * 10) == 0)
                {
                    // Check memory usage
                    long currentMemory = GC.GetTotalMemory(false);
                    Console.WriteLine($"  [Naive] Processed {i + BatchSize:N0} tokens | Memory: {currentMemory / 1024.0 / 1024.0:F2} MB");
                }
            }

            sw.Stop();
            long finalMemory = GC.GetTotalMemory(true);

            Console.WriteLine($"  [Naive] Completed in {sw.ElapsedMilliseconds}ms");
            Console.WriteLine($"  [Naive] Memory Delta: {(finalMemory - initialMemory) / 1024.0 / 1024.0:F2} MB");
            Console.WriteLine($"  [Naive] Gen 0 Collections: {GC.CollectionCount(0)}");
            Console.WriteLine($"  [Naive] Gen 1 Collections: {GC.CollectionCount(1)}");
            Console.WriteLine($"  [Naive] Gen 2 Collections: {GC.CollectionCount(2)}");
        }

        /// <summary>
        /// Simulates processing tokens using ArrayPool to reuse memory buffers.
        /// This minimizes allocations, reduces Gen 0 pressure, and prevents LOH fragmentation.
        /// </summary>
        private static async Task RunOptimizedTokenProcessing()
        {
            Console.WriteLine(">>> SCENARIO 2: Optimized Allocation (Low GC Pressure via ArrayPool)");

            var sw = Stopwatch.StartNew();
            long initialMemory = GC.GetTotalMemory(true);

            // Pre-calculate buffer size needed for the batch
            // We use ArrayPool<byte[]> to reuse arrays of string references.
            // This avoids the 'new string[]' allocation on the heap for every batch.
            var tokenPool = ArrayPool<string[]>.Shared;

            for (int i = 0; i < TotalTokensToProcess; i += BatchSize)
            {
                // Rent an array from the pool instead of allocating a new one.
                // If the pool is empty, it will allocate a new one (same cost as naive),
                // but subsequent iterations will reuse the memory.
                string[] tokenBatch = tokenPool.Rent(BatchSize);

                try
                {
                    // Initialize the batch
                    for (int j = 0; j < BatchSize; j++)
                    {
                        // We still allocate strings here (which are on the heap),
                        // but we avoid allocating the container array (which is on the heap).
                        // Note: To optimize further, we would also pool the string data buffers,
                        // but that requires custom types (e.g., Span<char> handling).
                        tokenBatch[j] = $"Token_{i + j}_Data_Payload_{Guid.NewGuid()}";
                    }

                    // Simulate processing
                    StringBuilder sb = new StringBuilder();
                    for (int j = 0; j < BatchSize; j++)
                    {
                        sb.Append(tokenBatch[j]);
                    }
                    string _ = sb.ToString();

                    if (i % (BatchSize * 10) == 0)
                    {
                        long currentMemory = GC.GetTotalMemory(false);
                        Console.WriteLine($"  [Optimized] Processed {i + BatchSize:N0} tokens | Memory: {currentMemory / 1024.0 / 1024.0:F2} MB");
                    }
                }
                finally
                {
                    // CRITICAL: Return the array to the pool so it can be reused.
                    // This marks the memory as available for the next loop iteration.
                    tokenPool.Return(tokenBatch);
                }
            }

            sw.Stop();
            long finalMemory = GC.GetTotalMemory(true);

            Console.WriteLine($"  [Optimized] Completed in {sw.ElapsedMilliseconds}ms");
            Console.WriteLine($"  [Optimized] Memory Delta: {(finalMemory - initialMemory) / 1024.0 / 1024.0:F2} MB");
            Console.WriteLine($"  [Optimized] Gen 0 Collections: {GC.CollectionCount(0)}");
            Console.WriteLine($"  [Optimized] Gen 1 Collections: {GC.CollectionCount(1)}");
            Console.WriteLine($"  [Optimized] Gen 2 Collections: {GC.CollectionCount(2)}");
        }
    }
}
